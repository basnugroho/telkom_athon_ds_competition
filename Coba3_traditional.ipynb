{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796b661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from datetime import datetime\n",
    "import env\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cedfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(sql_name):\n",
    "    # Connect to the MySQL database (replace the placeholders with your actual credentials)\n",
    "    host = env.db_host\n",
    "    user = env.db_user\n",
    "    password = env.db_password\n",
    "    database = env.db_schema\n",
    "    port = 33144\n",
    "\n",
    "    # Create a connection to the database\n",
    "    connection = mysql.connector.connect(host=host, user=user, password=password, database=database, port=port)\n",
    "\n",
    "    # Create a cursor object to execute the SQL query\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Define the SQL query\n",
    "    current_dir = f\"./\"\n",
    "    file_path = f'{current_dir}{sql_name}'\n",
    "\n",
    "    # Read the content of the file into a variable\n",
    "    with open(file_path, 'r') as file:\n",
    "        query = file.read()\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all the results into a list of tuples\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    # Get the column names from the cursor description\n",
    "    columns = [col[0] for col in cursor.description]\n",
    "\n",
    "    # Close the cursor and the connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    # Create a DataFrame from the results and column names\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dee60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mager maka auto hapus yg korelasi tinggi\n",
    "def remove_highly_correlated_features(df, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Menghapus fitur yang memiliki korelasi lebih dari ambang batas tertentu.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame yang berisi fitur-fitur yang akan diperiksa.\n",
    "    - threshold: Ambang batas korelasi.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame yang telah dikurangi fiturnya.\n",
    "    \"\"\"\n",
    "    # Hanya mengambil kolom numerik untuk korelasi\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    correlation_matrix = numeric_df.corr().abs()\n",
    "    \n",
    "    # Dapatkan matriks segitiga atas dari matriks korelasi\n",
    "    upper_triangle = correlation_matrix.where(\n",
    "        np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    #print(f\"kolom dengan korelasi di atas {threshold}: {upper_triangle.columns}\")\n",
    "    \n",
    "    # Temukan indeks kolom fitur yang memiliki korelasi lebih dari ambang batas\n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    \n",
    "    return df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852812b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_oversample(X, y):\n",
    "    # Dapatkan indeks dari kelas minoritas\n",
    "    minority_class_indices = y[y == 1].index\n",
    "    majority_class_indices = y[y == 0].index\n",
    "    \n",
    "    # Hitung jumlah kelas mayoritas\n",
    "    num_majority = len(y[y == 0])\n",
    "    \n",
    "    # Dapatkan sampel acak dari kelas minoritas\n",
    "    random_minority_indices = np.random.choice(minority_class_indices, num_majority, replace=True)\n",
    "    \n",
    "    # Gabungkan indeks kelas mayoritas dengan sampel acak dari kelas minoritas\n",
    "    over_sample_indices = np.concatenate([majority_class_indices, random_minority_indices])\n",
    "    \n",
    "    # Dapatkan data yang oversampled\n",
    "    X_oversampled = X.loc[over_sample_indices]\n",
    "    y_oversampled = y.loc[over_sample_indices]\n",
    "    \n",
    "    return X_oversampled, y_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174d5dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    7000\n",
      "0    7000\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ambil data dari DB\n",
    "df = run_query(\"coba5.sql\")\n",
    "class_counts = df['target'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826b6164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reco_id_curr</th>\n",
       "      <th>contract_type_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>own_car_flag</th>\n",
       "      <th>own_realty_flag</th>\n",
       "      <th>children_count</th>\n",
       "      <th>income</th>\n",
       "      <th>loan_body</th>\n",
       "      <th>annuity_payment</th>\n",
       "      <th>goods_price</th>\n",
       "      <th>...</th>\n",
       "      <th>document_20_flag</th>\n",
       "      <th>document_21_flag</th>\n",
       "      <th>requests_bki_hour</th>\n",
       "      <th>requests_bki_day</th>\n",
       "      <th>requests_bki_week</th>\n",
       "      <th>requests_bki_month</th>\n",
       "      <th>requests_bki_qrt</th>\n",
       "      <th>requests_bki_year</th>\n",
       "      <th>reco_id_curr</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16a5efff61d95fd7f8de14d186a69c01</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>30573.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16a5efff61d95fd7f8de14d186a69c01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbb7d8fa971b58cd1b19943f2b62f6ac</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>761872.0</td>\n",
       "      <td>70006.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>cbb7d8fa971b58cd1b19943f2b62f6ac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462a089891aa9e2f3b288835870e9dee</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>9949.5</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462a089891aa9e2f3b288835870e9dee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0db25409d914be200df6d9acf230c9ab</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>746280.0</td>\n",
       "      <td>54436.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0db25409d914be200df6d9acf230c9ab</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4c32decd9635cda528435f1091d948a</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>753840.0</td>\n",
       "      <td>27823.5</td>\n",
       "      <td>540000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c4c32decd9635cda528435f1091d948a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       reco_id_curr contract_type_name gender own_car_flag  \\\n",
       "0  16a5efff61d95fd7f8de14d186a69c01         Cash loans      F            N   \n",
       "1  cbb7d8fa971b58cd1b19943f2b62f6ac         Cash loans      M            Y   \n",
       "2  462a089891aa9e2f3b288835870e9dee         Cash loans      F            N   \n",
       "3  0db25409d914be200df6d9acf230c9ab         Cash loans      M            N   \n",
       "4  c4c32decd9635cda528435f1091d948a         Cash loans      F            N   \n",
       "\n",
       "  own_realty_flag  children_count    income  loan_body  annuity_payment  \\\n",
       "0               Y               2   99000.0   450000.0          30573.0   \n",
       "1               N               2  180000.0   761872.0          70006.5   \n",
       "2               Y               0   99000.0   152820.0           9949.5   \n",
       "3               Y               0  225000.0   746280.0          54436.5   \n",
       "4               Y               1  270000.0   753840.0          27823.5   \n",
       "\n",
       "   goods_price  ... document_20_flag document_21_flag requests_bki_hour  \\\n",
       "0     450000.0  ...                0                0               0.0   \n",
       "1     675000.0  ...                0                0               0.0   \n",
       "2     135000.0  ...                0                0               0.0   \n",
       "3     675000.0  ...                0                0               0.0   \n",
       "4     540000.0  ...                0                0               0.0   \n",
       "\n",
       "  requests_bki_day requests_bki_week  requests_bki_month  requests_bki_qrt  \\\n",
       "0              0.0               0.0                 0.0               0.0   \n",
       "1              0.0               0.0                 2.0               0.0   \n",
       "2              0.0               0.0                 0.0               1.0   \n",
       "3              0.0               0.0                 1.0               0.0   \n",
       "4              0.0               0.0                 0.0               0.0   \n",
       "\n",
       "   requests_bki_year                      reco_id_curr  target  \n",
       "0                1.0  16a5efff61d95fd7f8de14d186a69c01       1  \n",
       "1                9.0  cbb7d8fa971b58cd1b19943f2b62f6ac       1  \n",
       "2                0.0  462a089891aa9e2f3b288835870e9dee       1  \n",
       "3                6.0  0db25409d914be200df6d9acf230c9ab       1  \n",
       "4                0.0  c4c32decd9635cda528435f1091d948a       1  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 150\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b7bae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reco_id_curr                          0\n",
       "contract_type_name                    0\n",
       "gender                                0\n",
       "own_car_flag                          0\n",
       "own_realty_flag                       0\n",
       "children_count                        0\n",
       "income                                0\n",
       "loan_body                             0\n",
       "annuity_payment                       0\n",
       "goods_price                           0\n",
       "type_suite_name                       0\n",
       "income_type_name                      0\n",
       "education_type_name                   0\n",
       "family_status_name                    0\n",
       "housing_type_name                     0\n",
       "population_relative_region            0\n",
       "days_birth                            0\n",
       "days_employed                         0\n",
       "registration_timestamp                0\n",
       "publication_timestamp                 0\n",
       "age_own_car                           0\n",
       "mobile_flag                           0\n",
       "employee_phone_flag                   0\n",
       "work_phone_flag                       0\n",
       "mobile_contact_flag                   0\n",
       "phone_flag                            0\n",
       "email_flag                            0\n",
       "type_of_occupation                    0\n",
       "family_members__count                 0\n",
       "rating_client_region                  0\n",
       "rating_client_w_city_region           0\n",
       "start_weekday_appr_process            0\n",
       "hour_of_approval_process_start        0\n",
       "not_live_region_reg_region            0\n",
       "not_work_region_reg_region            0\n",
       "living_region_not_work_region_flag    0\n",
       "not_live_city_reg_city                0\n",
       "not_work_city_reg_city                0\n",
       "living_city_not_work_city_flag        0\n",
       "type_of_organization                  0\n",
       "external_source_1                     0\n",
       "external_source_2                     0\n",
       "external_source_3                     0\n",
       "average_apartments                    0\n",
       "average_basementarea                  0\n",
       "average_years_beginexpluatation       0\n",
       "average_years_building                0\n",
       "average_commonarea                    0\n",
       "average_elevator_count                0\n",
       "average_entrance_count                0\n",
       "average_max_floors                    0\n",
       "average_min_floors                    0\n",
       "average_land_area                     0\n",
       "average_living_apartments             0\n",
       "average_living_area                   0\n",
       "non_living_apartments_av              0\n",
       "non_living_area_avg                   0\n",
       "mode_apartments                       0\n",
       "mode_basementarea                     0\n",
       "mode_years_beginexpluatation          0\n",
       "mode_years_building                   0\n",
       "mode_commonarea                       0\n",
       "mode_elevator_count                   0\n",
       "mode_entrance_count                   0\n",
       "mode_max_floors                       0\n",
       "mode_min_floors                       0\n",
       "mode_land_area                        0\n",
       "mode_living_apartments                0\n",
       "mode_living_area                      0\n",
       "non_living_apartments_mode            0\n",
       "non_living_area_mode                  0\n",
       "median_apartments                     0\n",
       "median_basementarea                   0\n",
       "median_years_beginexpluatation        0\n",
       "median_years_building                 0\n",
       "median_commonarea                     0\n",
       "median_elevator_count                 0\n",
       "median_entrance_count                 0\n",
       "median_max_floors                     0\n",
       "median_min_floors                     0\n",
       "median_land_area                      0\n",
       "median_living_apartments              0\n",
       "median_living_area                    0\n",
       "non_living_apartments_medi            0\n",
       "non_living_area_medi                  0\n",
       "fondkapremon_mode                     0\n",
       "mode_house_type                       0\n",
       "mode_total_area                       0\n",
       "mode_walls_material                   0\n",
       "emergency_state_mode                  0\n",
       "observes_30_count_social_circle       0\n",
       "social_circle_defaults_30_days        0\n",
       "observes_60_count_social_circle       0\n",
       "social_circle_defaults_60_days        0\n",
       "last_phone_number_change              0\n",
       "document_2_flag                       0\n",
       "document_3_flag                       0\n",
       "document_4_flag                       0\n",
       "document_5_flag                       0\n",
       "document_6_flag                       0\n",
       "document_7_flag                       0\n",
       "document_8_flag                       0\n",
       "document_9_flag                       0\n",
       "document_10_flag                      0\n",
       "document_11_flag                      0\n",
       "document_12_flag                      0\n",
       "document_13_flag                      0\n",
       "document_14_flag                      0\n",
       "document_15_flag                      0\n",
       "document_16_flag                      0\n",
       "document_17_flag                      0\n",
       "document_18_flag                      0\n",
       "document_19_flag                      0\n",
       "document_20_flag                      0\n",
       "document_21_flag                      0\n",
       "requests_bki_hour                     0\n",
       "requests_bki_day                      0\n",
       "requests_bki_week                     0\n",
       "requests_bki_month                    0\n",
       "requests_bki_qrt                      0\n",
       "requests_bki_year                     0\n",
       "reco_id_curr                          0\n",
       "target                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b995a775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Ambil data dari DB\n",
    "#df = run_query(\"coba6.sql\")\n",
    "\n",
    "# Menghapus kolom ID\n",
    "df.drop(columns=['reco_id_curr'], inplace=True)\n",
    "\n",
    "# Mengisi missing values\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Label Encoding kolom kategorikal\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split Train vs Test Data\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Penskalaan fitur\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Resample\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_df.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train_resampled, y_train_resampled = manual_oversample(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b509c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.6711\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67      1385\n",
      "           1       0.67      0.68      0.68      1415\n",
      "\n",
      "    accuracy                           0.67      2800\n",
      "   macro avg       0.67      0.67      0.67      2800\n",
      "weighted avg       0.67      0.67      0.67      2800\n",
      "\n",
      "ROC AUC Score: 0.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi dengan kelas\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "# Prediksi dengan probabilitas\n",
    "y_pred_prob = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Menyimpan model, scaler, dan encoders\n",
    "joblib.dump(lr, 'logistic_regression_model.pkl')\n",
    "joblib.dump(scaler, 'data_scaler.pkl')\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0ca5c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "Accuracy Score: 0.6465\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.83      0.70       986\n",
      "           1       0.74      0.47      0.57      1014\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.67      0.65      0.64      2000\n",
      "weighted avg       0.67      0.65      0.63      2000\n",
      "\n",
      "ROC AUC Score: 0.7252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ... [kode sebelumnya]\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi dengan kelas\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "# Prediksi dengan probabilitas\n",
    "y_pred_prob_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nRandom Forest Results:\")\n",
    "print(f\"Accuracy Score: {accuracy_rf:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_rf)\n",
    "print(f\"ROC AUC Score: {roc_auc_rf:.4f}\")\n",
    "\n",
    "# Menyimpan model RandomForest\n",
    "joblib.dump(rf, 'random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd2e6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "Accuracy Score: 0.6486\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67      1385\n",
      "           1       0.68      0.57      0.62      1415\n",
      "\n",
      "    accuracy                           0.65      2800\n",
      "   macro avg       0.65      0.65      0.65      2800\n",
      "weighted avg       0.65      0.65      0.65      2800\n",
      "\n",
      "ROC AUC Score: 0.7023\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Pelatihan model XGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "y_pred_prob_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_prob_xgb)\n",
    "report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\nXGBoost Results:\")\n",
    "print(f\"Accuracy Score: {accuracy_xgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_xgb)\n",
    "print(f\"ROC AUC Score: {roc_auc_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "039d3047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "Accuracy Score: 0.6707\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      1385\n",
      "           1       0.69      0.64      0.66      1415\n",
      "\n",
      "    accuracy                           0.67      2800\n",
      "   macro avg       0.67      0.67      0.67      2800\n",
      "weighted avg       0.67      0.67      0.67      2800\n",
      "\n",
      "ROC AUC Score: 0.7358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_model.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Pelatihan model XGBoost\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\", n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "y_pred_prob_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_prob_xgb)\n",
    "report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\nXGBoost Results:\")\n",
    "print(f\"Accuracy Score: {accuracy_xgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_xgb)\n",
    "print(f\"ROC AUC Score: {roc_auc_xgb:.4f}\")\n",
    "# Menyimpan model XGBoost\n",
    "joblib.dump(xgb_model, 'xgboost_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774c6091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5615, number of negative: 5615\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10105\n",
      "[LightGBM] [Info] Number of data points in the train set: 11230, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LightGBM Results:\n",
      "Accuracy Score: 0.6729\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.68      1385\n",
      "           1       0.69      0.63      0.66      1415\n",
      "\n",
      "    accuracy                           0.67      2800\n",
      "   macro avg       0.67      0.67      0.67      2800\n",
      "weighted avg       0.67      0.67      0.67      2800\n",
      "\n",
      "ROC AUC Score: 0.7310\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Pelatihan model LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "lgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "y_pred_prob_lgb = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, y_pred_prob_lgb)\n",
    "report_lgb = classification_report(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"\\nLightGBM Results:\")\n",
    "print(f\"Accuracy Score: {accuracy_lgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_lgb)\n",
    "print(f\"ROC AUC Score: {roc_auc_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c104dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5615, number of negative: 5615\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10105\n",
      "[LightGBM] [Info] Number of data points in the train set: 11230, number of used features: 105\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "\n",
      "LightGBM Results:\n",
      "Accuracy Score: 0.6736\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      1385\n",
      "           1       0.69      0.64      0.66      1415\n",
      "\n",
      "    accuracy                           0.67      2800\n",
      "   macro avg       0.67      0.67      0.67      2800\n",
      "weighted avg       0.67      0.67      0.67      2800\n",
      "\n",
      "ROC AUC Score: 0.7382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lightgbm_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Pelatihan model LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(metric=\"auc\", n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "lgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "y_pred_prob_lgb = lgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y_test, y_pred_prob_lgb)\n",
    "report_lgb = classification_report(y_test, y_pred_lgb)\n",
    "\n",
    "print(f\"\\nLightGBM Results:\")\n",
    "print(f\"Accuracy Score: {accuracy_lgb:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_lgb)\n",
    "print(f\"ROC AUC Score: {roc_auc_lgb:.4f}\")\n",
    "\n",
    "# Menyimpan model LightGBM\n",
    "joblib.dump(lgb_model, 'lightgbm_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7325b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Results:\n",
      "Accuracy Score: 0.6679\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      1385\n",
      "           1       0.67      0.68      0.67      1415\n",
      "\n",
      "    accuracy                           0.67      2800\n",
      "   macro avg       0.67      0.67      0.67      2800\n",
      "weighted avg       0.67      0.67      0.67      2800\n",
      "\n",
      "ROC AUC Score: 0.7283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Pelatihan model SVM\n",
    "svm_model = SVC(kernel='linear', probability=True, random_state=42) # 'probability=True' agar bisa memanggil predict_proba\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "y_pred_prob_svm = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluasi model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_prob_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"\\nSVM Results:\")\n",
    "print(f\"Accuracy Score: {accuracy_svm:.4f}\")\n",
    "print(\"Classification Report:\\n\", report_svm)\n",
    "print(f\"ROC AUC Score: {roc_auc_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50005772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "280/280 [==============================] - 0s 949us/step - loss: 0.6559 - accuracy: 0.6263 - val_loss: 0.6343 - val_accuracy: 0.6571\n",
      "Epoch 2/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.6151 - accuracy: 0.6699 - val_loss: 0.6330 - val_accuracy: 0.6531\n",
      "Epoch 3/100\n",
      "280/280 [==============================] - 0s 708us/step - loss: 0.6006 - accuracy: 0.6836 - val_loss: 0.6382 - val_accuracy: 0.6509\n",
      "Epoch 4/100\n",
      "280/280 [==============================] - 0s 697us/step - loss: 0.5926 - accuracy: 0.6901 - val_loss: 0.6451 - val_accuracy: 0.6576\n",
      "Epoch 5/100\n",
      "280/280 [==============================] - 0s 703us/step - loss: 0.5828 - accuracy: 0.6967 - val_loss: 0.6441 - val_accuracy: 0.6518\n",
      "Epoch 6/100\n",
      "280/280 [==============================] - 0s 708us/step - loss: 0.5726 - accuracy: 0.7032 - val_loss: 0.6452 - val_accuracy: 0.6522\n",
      "Epoch 7/100\n",
      "280/280 [==============================] - 0s 692us/step - loss: 0.5681 - accuracy: 0.7080 - val_loss: 0.6498 - val_accuracy: 0.6487\n",
      "Epoch 8/100\n",
      "280/280 [==============================] - 0s 688us/step - loss: 0.5592 - accuracy: 0.7163 - val_loss: 0.6505 - val_accuracy: 0.6473\n",
      "Epoch 9/100\n",
      "280/280 [==============================] - 0s 722us/step - loss: 0.5477 - accuracy: 0.7223 - val_loss: 0.6715 - val_accuracy: 0.6455\n",
      "Epoch 10/100\n",
      "280/280 [==============================] - 0s 713us/step - loss: 0.5403 - accuracy: 0.7240 - val_loss: 0.6709 - val_accuracy: 0.6420\n",
      "Epoch 11/100\n",
      "280/280 [==============================] - 0s 708us/step - loss: 0.5327 - accuracy: 0.7369 - val_loss: 0.6700 - val_accuracy: 0.6259\n",
      "Epoch 12/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.5267 - accuracy: 0.7377 - val_loss: 0.6838 - val_accuracy: 0.6384\n",
      "Epoch 13/100\n",
      "280/280 [==============================] - 0s 713us/step - loss: 0.5178 - accuracy: 0.7480 - val_loss: 0.6916 - val_accuracy: 0.6357\n",
      "Epoch 14/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.5110 - accuracy: 0.7429 - val_loss: 0.6940 - val_accuracy: 0.6384\n",
      "Epoch 15/100\n",
      "280/280 [==============================] - 0s 818us/step - loss: 0.5021 - accuracy: 0.7528 - val_loss: 0.6958 - val_accuracy: 0.6429\n",
      "Epoch 16/100\n",
      "280/280 [==============================] - 0s 681us/step - loss: 0.4899 - accuracy: 0.7585 - val_loss: 0.7022 - val_accuracy: 0.6272\n",
      "Epoch 17/100\n",
      "280/280 [==============================] - 0s 670us/step - loss: 0.4840 - accuracy: 0.7677 - val_loss: 0.7150 - val_accuracy: 0.6299\n",
      "Epoch 18/100\n",
      "280/280 [==============================] - 0s 677us/step - loss: 0.4775 - accuracy: 0.7704 - val_loss: 0.7217 - val_accuracy: 0.6339\n",
      "Epoch 19/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.4683 - accuracy: 0.7711 - val_loss: 0.7232 - val_accuracy: 0.6250\n",
      "Epoch 20/100\n",
      "280/280 [==============================] - 0s 701us/step - loss: 0.4658 - accuracy: 0.7817 - val_loss: 0.7394 - val_accuracy: 0.6348\n",
      "Epoch 21/100\n",
      "280/280 [==============================] - 0s 683us/step - loss: 0.4583 - accuracy: 0.7809 - val_loss: 0.7544 - val_accuracy: 0.6196\n",
      "Epoch 22/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.4492 - accuracy: 0.7879 - val_loss: 0.7547 - val_accuracy: 0.6268\n",
      "Epoch 23/100\n",
      "280/280 [==============================] - 0s 668us/step - loss: 0.4404 - accuracy: 0.7953 - val_loss: 0.7719 - val_accuracy: 0.6210\n",
      "Epoch 24/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.4335 - accuracy: 0.7958 - val_loss: 0.7600 - val_accuracy: 0.6219\n",
      "Epoch 25/100\n",
      "280/280 [==============================] - 0s 661us/step - loss: 0.4241 - accuracy: 0.8017 - val_loss: 0.7925 - val_accuracy: 0.6143\n",
      "Epoch 26/100\n",
      "280/280 [==============================] - 0s 660us/step - loss: 0.4163 - accuracy: 0.8075 - val_loss: 0.8111 - val_accuracy: 0.6125\n",
      "Epoch 27/100\n",
      "280/280 [==============================] - 0s 657us/step - loss: 0.4163 - accuracy: 0.8049 - val_loss: 0.7967 - val_accuracy: 0.6299\n",
      "Epoch 28/100\n",
      "280/280 [==============================] - 0s 664us/step - loss: 0.4098 - accuracy: 0.8065 - val_loss: 0.8009 - val_accuracy: 0.6125\n",
      "Epoch 29/100\n",
      "280/280 [==============================] - 0s 681us/step - loss: 0.4023 - accuracy: 0.8100 - val_loss: 0.8300 - val_accuracy: 0.6313\n",
      "Epoch 30/100\n",
      "280/280 [==============================] - 0s 678us/step - loss: 0.4014 - accuracy: 0.8142 - val_loss: 0.8202 - val_accuracy: 0.6192\n",
      "Epoch 31/100\n",
      "280/280 [==============================] - 0s 678us/step - loss: 0.3951 - accuracy: 0.8223 - val_loss: 0.8194 - val_accuracy: 0.6170\n",
      "Epoch 32/100\n",
      "280/280 [==============================] - 0s 670us/step - loss: 0.3860 - accuracy: 0.8224 - val_loss: 0.8351 - val_accuracy: 0.6103\n",
      "Epoch 33/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.3808 - accuracy: 0.8259 - val_loss: 0.8548 - val_accuracy: 0.6156\n",
      "Epoch 34/100\n",
      "280/280 [==============================] - 0s 671us/step - loss: 0.3843 - accuracy: 0.8288 - val_loss: 0.8563 - val_accuracy: 0.6277\n",
      "Epoch 35/100\n",
      "280/280 [==============================] - 0s 668us/step - loss: 0.3726 - accuracy: 0.8313 - val_loss: 0.8603 - val_accuracy: 0.6085\n",
      "Epoch 36/100\n",
      "280/280 [==============================] - 0s 663us/step - loss: 0.3656 - accuracy: 0.8356 - val_loss: 0.8799 - val_accuracy: 0.6254\n",
      "Epoch 37/100\n",
      "280/280 [==============================] - 0s 663us/step - loss: 0.3678 - accuracy: 0.8387 - val_loss: 0.8784 - val_accuracy: 0.6192\n",
      "Epoch 38/100\n",
      "280/280 [==============================] - 0s 662us/step - loss: 0.3622 - accuracy: 0.8404 - val_loss: 0.8815 - val_accuracy: 0.6201\n",
      "Epoch 39/100\n",
      "280/280 [==============================] - 0s 672us/step - loss: 0.3523 - accuracy: 0.8416 - val_loss: 0.9009 - val_accuracy: 0.6254\n",
      "Epoch 40/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.3451 - accuracy: 0.8510 - val_loss: 0.9153 - val_accuracy: 0.6147\n",
      "Epoch 41/100\n",
      "280/280 [==============================] - 0s 670us/step - loss: 0.3396 - accuracy: 0.8483 - val_loss: 0.9099 - val_accuracy: 0.6045\n",
      "Epoch 42/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.3452 - accuracy: 0.8482 - val_loss: 0.9029 - val_accuracy: 0.6161\n",
      "Epoch 43/100\n",
      "280/280 [==============================] - 0s 689us/step - loss: 0.3396 - accuracy: 0.8493 - val_loss: 0.9270 - val_accuracy: 0.6170\n",
      "Epoch 44/100\n",
      "280/280 [==============================] - 0s 674us/step - loss: 0.3442 - accuracy: 0.8449 - val_loss: 0.9110 - val_accuracy: 0.6134\n",
      "Epoch 45/100\n",
      "280/280 [==============================] - 0s 662us/step - loss: 0.3300 - accuracy: 0.8539 - val_loss: 0.9223 - val_accuracy: 0.6174\n",
      "Epoch 46/100\n",
      "280/280 [==============================] - 0s 675us/step - loss: 0.3203 - accuracy: 0.8577 - val_loss: 0.9379 - val_accuracy: 0.6254\n",
      "Epoch 47/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.3276 - accuracy: 0.8531 - val_loss: 0.9513 - val_accuracy: 0.6062\n",
      "Epoch 48/100\n",
      "280/280 [==============================] - 0s 672us/step - loss: 0.3282 - accuracy: 0.8564 - val_loss: 0.9383 - val_accuracy: 0.6121\n",
      "Epoch 49/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.3203 - accuracy: 0.8605 - val_loss: 0.9573 - val_accuracy: 0.6062\n",
      "Epoch 50/100\n",
      "280/280 [==============================] - 0s 672us/step - loss: 0.3176 - accuracy: 0.8592 - val_loss: 0.9725 - val_accuracy: 0.6094\n",
      "Epoch 51/100\n",
      "280/280 [==============================] - 0s 707us/step - loss: 0.3122 - accuracy: 0.8656 - val_loss: 0.9846 - val_accuracy: 0.6085\n",
      "Epoch 52/100\n",
      "280/280 [==============================] - 0s 670us/step - loss: 0.3107 - accuracy: 0.8666 - val_loss: 1.0113 - val_accuracy: 0.6027\n",
      "Epoch 53/100\n",
      "280/280 [==============================] - 0s 674us/step - loss: 0.3069 - accuracy: 0.8660 - val_loss: 1.0007 - val_accuracy: 0.6143\n",
      "Epoch 54/100\n",
      "280/280 [==============================] - 0s 832us/step - loss: 0.2977 - accuracy: 0.8679 - val_loss: 1.0128 - val_accuracy: 0.6058\n",
      "Epoch 55/100\n",
      "280/280 [==============================] - 0s 678us/step - loss: 0.2999 - accuracy: 0.8703 - val_loss: 1.0183 - val_accuracy: 0.6121\n",
      "Epoch 56/100\n",
      "280/280 [==============================] - 0s 666us/step - loss: 0.2988 - accuracy: 0.8704 - val_loss: 1.0463 - val_accuracy: 0.6045\n",
      "Epoch 57/100\n",
      "280/280 [==============================] - 0s 674us/step - loss: 0.2950 - accuracy: 0.8690 - val_loss: 1.0259 - val_accuracy: 0.6196\n",
      "Epoch 58/100\n",
      "280/280 [==============================] - 0s 776us/step - loss: 0.2931 - accuracy: 0.8723 - val_loss: 1.0219 - val_accuracy: 0.6152\n",
      "Epoch 59/100\n",
      "280/280 [==============================] - 0s 710us/step - loss: 0.2916 - accuracy: 0.8737 - val_loss: 1.0455 - val_accuracy: 0.6152\n",
      "Epoch 60/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.2940 - accuracy: 0.8748 - val_loss: 1.0595 - val_accuracy: 0.6165\n",
      "Epoch 61/100\n",
      "280/280 [==============================] - 0s 745us/step - loss: 0.2873 - accuracy: 0.8765 - val_loss: 1.0520 - val_accuracy: 0.6062\n",
      "Epoch 62/100\n",
      "280/280 [==============================] - 0s 711us/step - loss: 0.2788 - accuracy: 0.8797 - val_loss: 1.0570 - val_accuracy: 0.6098\n",
      "Epoch 63/100\n",
      "280/280 [==============================] - 0s 671us/step - loss: 0.2762 - accuracy: 0.8854 - val_loss: 1.0534 - val_accuracy: 0.6116\n",
      "Epoch 64/100\n",
      "280/280 [==============================] - 0s 673us/step - loss: 0.2870 - accuracy: 0.8768 - val_loss: 1.0617 - val_accuracy: 0.6094\n",
      "Epoch 65/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.2750 - accuracy: 0.8791 - val_loss: 1.0750 - val_accuracy: 0.6013\n",
      "Epoch 66/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.2698 - accuracy: 0.8854 - val_loss: 1.1062 - val_accuracy: 0.6058\n",
      "Epoch 67/100\n",
      "280/280 [==============================] - 0s 700us/step - loss: 0.2635 - accuracy: 0.8881 - val_loss: 1.0974 - val_accuracy: 0.6049\n",
      "Epoch 68/100\n",
      "280/280 [==============================] - 0s 690us/step - loss: 0.2741 - accuracy: 0.8826 - val_loss: 1.1317 - val_accuracy: 0.5924\n",
      "Epoch 69/100\n",
      "280/280 [==============================] - 0s 696us/step - loss: 0.2624 - accuracy: 0.8894 - val_loss: 1.1106 - val_accuracy: 0.5960\n",
      "Epoch 70/100\n",
      "280/280 [==============================] - 0s 686us/step - loss: 0.2628 - accuracy: 0.8913 - val_loss: 1.1043 - val_accuracy: 0.6107\n",
      "Epoch 71/100\n",
      "280/280 [==============================] - 0s 694us/step - loss: 0.2591 - accuracy: 0.8902 - val_loss: 1.1579 - val_accuracy: 0.6036\n",
      "Epoch 72/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.2648 - accuracy: 0.8874 - val_loss: 1.1374 - val_accuracy: 0.6116\n",
      "Epoch 73/100\n",
      "280/280 [==============================] - 0s 666us/step - loss: 0.2631 - accuracy: 0.8900 - val_loss: 1.1541 - val_accuracy: 0.6018\n",
      "Epoch 74/100\n",
      "280/280 [==============================] - 0s 658us/step - loss: 0.2708 - accuracy: 0.8854 - val_loss: 1.1333 - val_accuracy: 0.5946\n",
      "Epoch 75/100\n",
      "280/280 [==============================] - 0s 670us/step - loss: 0.2468 - accuracy: 0.8965 - val_loss: 1.1619 - val_accuracy: 0.6027\n",
      "Epoch 76/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.2482 - accuracy: 0.8968 - val_loss: 1.1702 - val_accuracy: 0.6031\n",
      "Epoch 77/100\n",
      "280/280 [==============================] - 0s 673us/step - loss: 0.2608 - accuracy: 0.8874 - val_loss: 1.1739 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "280/280 [==============================] - 0s 674us/step - loss: 0.2637 - accuracy: 0.8865 - val_loss: 1.1675 - val_accuracy: 0.5991\n",
      "Epoch 79/100\n",
      "280/280 [==============================] - 0s 670us/step - loss: 0.2512 - accuracy: 0.8945 - val_loss: 1.1427 - val_accuracy: 0.6067\n",
      "Epoch 80/100\n",
      "280/280 [==============================] - 0s 671us/step - loss: 0.2549 - accuracy: 0.8927 - val_loss: 1.1688 - val_accuracy: 0.6031\n",
      "Epoch 81/100\n",
      "280/280 [==============================] - 0s 673us/step - loss: 0.2406 - accuracy: 0.8968 - val_loss: 1.1674 - val_accuracy: 0.6054\n",
      "Epoch 82/100\n",
      "280/280 [==============================] - 0s 669us/step - loss: 0.2571 - accuracy: 0.8929 - val_loss: 1.1896 - val_accuracy: 0.5938\n",
      "Epoch 83/100\n",
      "280/280 [==============================] - 0s 761us/step - loss: 0.2381 - accuracy: 0.9022 - val_loss: 1.1981 - val_accuracy: 0.5996\n",
      "Epoch 84/100\n",
      "280/280 [==============================] - 0s 665us/step - loss: 0.2499 - accuracy: 0.8944 - val_loss: 1.1963 - val_accuracy: 0.6107\n",
      "Epoch 85/100\n",
      "280/280 [==============================] - 0s 668us/step - loss: 0.2448 - accuracy: 0.8994 - val_loss: 1.2235 - val_accuracy: 0.5969\n",
      "Epoch 86/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.2377 - accuracy: 0.9006 - val_loss: 1.2351 - val_accuracy: 0.5964\n",
      "Epoch 87/100\n",
      "280/280 [==============================] - 0s 667us/step - loss: 0.2361 - accuracy: 0.8983 - val_loss: 1.2337 - val_accuracy: 0.5929\n",
      "Epoch 88/100\n",
      "280/280 [==============================] - 0s 665us/step - loss: 0.2363 - accuracy: 0.9052 - val_loss: 1.2315 - val_accuracy: 0.6040\n",
      "Epoch 89/100\n",
      "280/280 [==============================] - 0s 668us/step - loss: 0.2339 - accuracy: 0.9049 - val_loss: 1.2331 - val_accuracy: 0.6062\n",
      "Epoch 90/100\n",
      "280/280 [==============================] - 0s 675us/step - loss: 0.2317 - accuracy: 0.9021 - val_loss: 1.2494 - val_accuracy: 0.6018\n",
      "Epoch 91/100\n",
      "280/280 [==============================] - 0s 674us/step - loss: 0.2303 - accuracy: 0.9050 - val_loss: 1.2532 - val_accuracy: 0.6071\n",
      "Epoch 92/100\n",
      "280/280 [==============================] - 0s 703us/step - loss: 0.2401 - accuracy: 0.8981 - val_loss: 1.2182 - val_accuracy: 0.6022\n",
      "Epoch 93/100\n",
      "280/280 [==============================] - 0s 689us/step - loss: 0.2400 - accuracy: 0.9028 - val_loss: 1.2490 - val_accuracy: 0.5906\n",
      "Epoch 94/100\n",
      "280/280 [==============================] - 0s 768us/step - loss: 0.2391 - accuracy: 0.8984 - val_loss: 1.2270 - val_accuracy: 0.6045\n",
      "Epoch 95/100\n",
      "280/280 [==============================] - 0s 778us/step - loss: 0.2320 - accuracy: 0.9029 - val_loss: 1.2163 - val_accuracy: 0.5969\n",
      "Epoch 96/100\n",
      "280/280 [==============================] - 0s 767us/step - loss: 0.2292 - accuracy: 0.9047 - val_loss: 1.2421 - val_accuracy: 0.6049\n",
      "Epoch 97/100\n",
      "280/280 [==============================] - 0s 864us/step - loss: 0.2269 - accuracy: 0.9066 - val_loss: 1.2434 - val_accuracy: 0.5951\n",
      "Epoch 98/100\n",
      "280/280 [==============================] - 0s 719us/step - loss: 0.2205 - accuracy: 0.9112 - val_loss: 1.2423 - val_accuracy: 0.6125\n",
      "Epoch 99/100\n",
      "280/280 [==============================] - 0s 701us/step - loss: 0.2220 - accuracy: 0.9125 - val_loss: 1.2819 - val_accuracy: 0.5911\n",
      "Epoch 100/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.2222 - accuracy: 0.9074 - val_loss: 1.2420 - val_accuracy: 0.5982\n",
      "88/88 [==============================] - 0s 349us/step\n",
      "ROC AUC Score: 0.6434\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Membangun model dengan TensorFlow\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(n_features,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluasi Model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC AUC Score: {roc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51b7e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "280/280 [==============================] - 0s 922us/step - loss: 0.6617 - accuracy: 0.6228 - val_loss: 0.6361 - val_accuracy: 0.6482\n",
      "Epoch 2/100\n",
      "280/280 [==============================] - 0s 713us/step - loss: 0.6252 - accuracy: 0.6622 - val_loss: 0.6346 - val_accuracy: 0.6580\n",
      "Epoch 3/100\n",
      "280/280 [==============================] - 0s 713us/step - loss: 0.6063 - accuracy: 0.6820 - val_loss: 0.6343 - val_accuracy: 0.6567\n",
      "Epoch 4/100\n",
      "280/280 [==============================] - 0s 709us/step - loss: 0.5994 - accuracy: 0.6881 - val_loss: 0.6333 - val_accuracy: 0.6500\n",
      "Epoch 5/100\n",
      "280/280 [==============================] - 0s 771us/step - loss: 0.5939 - accuracy: 0.6839 - val_loss: 0.6336 - val_accuracy: 0.6536\n",
      "Epoch 6/100\n",
      "280/280 [==============================] - 0s 772us/step - loss: 0.5852 - accuracy: 0.6943 - val_loss: 0.6354 - val_accuracy: 0.6594\n",
      "Epoch 7/100\n",
      "280/280 [==============================] - 0s 790us/step - loss: 0.5794 - accuracy: 0.7016 - val_loss: 0.6377 - val_accuracy: 0.6558\n",
      "Epoch 8/100\n",
      "280/280 [==============================] - 0s 786us/step - loss: 0.5721 - accuracy: 0.7064 - val_loss: 0.6406 - val_accuracy: 0.6585\n",
      "Epoch 9/100\n",
      "280/280 [==============================] - 0s 789us/step - loss: 0.5683 - accuracy: 0.7093 - val_loss: 0.6467 - val_accuracy: 0.6513\n",
      "Epoch 10/100\n",
      "280/280 [==============================] - 0s 781us/step - loss: 0.5610 - accuracy: 0.7102 - val_loss: 0.6463 - val_accuracy: 0.6509\n",
      "Epoch 11/100\n",
      "280/280 [==============================] - 0s 728us/step - loss: 0.5551 - accuracy: 0.7128 - val_loss: 0.6575 - val_accuracy: 0.6500\n",
      "Epoch 12/100\n",
      "280/280 [==============================] - 0s 817us/step - loss: 0.5488 - accuracy: 0.7199 - val_loss: 0.6452 - val_accuracy: 0.6469\n",
      "Epoch 13/100\n",
      "280/280 [==============================] - 0s 740us/step - loss: 0.5446 - accuracy: 0.7210 - val_loss: 0.6486 - val_accuracy: 0.6424\n",
      "Epoch 14/100\n",
      "280/280 [==============================] - 0s 710us/step - loss: 0.5356 - accuracy: 0.7356 - val_loss: 0.6650 - val_accuracy: 0.6554\n",
      "Epoch 15/100\n",
      "280/280 [==============================] - 0s 711us/step - loss: 0.5274 - accuracy: 0.7331 - val_loss: 0.6590 - val_accuracy: 0.6509\n",
      "Epoch 16/100\n",
      "280/280 [==============================] - 0s 701us/step - loss: 0.5258 - accuracy: 0.7358 - val_loss: 0.6730 - val_accuracy: 0.6424\n",
      "Epoch 17/100\n",
      "280/280 [==============================] - 0s 851us/step - loss: 0.5179 - accuracy: 0.7375 - val_loss: 0.6706 - val_accuracy: 0.6429\n",
      "Epoch 18/100\n",
      "280/280 [==============================] - 0s 707us/step - loss: 0.5108 - accuracy: 0.7445 - val_loss: 0.6869 - val_accuracy: 0.6406\n",
      "Epoch 19/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.5065 - accuracy: 0.7465 - val_loss: 0.6807 - val_accuracy: 0.6402\n",
      "Epoch 20/100\n",
      "280/280 [==============================] - 0s 744us/step - loss: 0.5008 - accuracy: 0.7488 - val_loss: 0.6780 - val_accuracy: 0.6429\n",
      "Epoch 21/100\n",
      "280/280 [==============================] - 0s 787us/step - loss: 0.4965 - accuracy: 0.7546 - val_loss: 0.6887 - val_accuracy: 0.6344\n",
      "Epoch 22/100\n",
      "280/280 [==============================] - 0s 700us/step - loss: 0.4895 - accuracy: 0.7577 - val_loss: 0.6935 - val_accuracy: 0.6402\n",
      "Epoch 23/100\n",
      "280/280 [==============================] - 0s 701us/step - loss: 0.4877 - accuracy: 0.7621 - val_loss: 0.6918 - val_accuracy: 0.6482\n",
      "Epoch 24/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.4792 - accuracy: 0.7614 - val_loss: 0.6917 - val_accuracy: 0.6487\n",
      "Epoch 25/100\n",
      "280/280 [==============================] - 0s 702us/step - loss: 0.4741 - accuracy: 0.7674 - val_loss: 0.7025 - val_accuracy: 0.6433\n",
      "Epoch 26/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.4622 - accuracy: 0.7773 - val_loss: 0.7110 - val_accuracy: 0.6362\n",
      "Epoch 27/100\n",
      "280/280 [==============================] - 0s 702us/step - loss: 0.4676 - accuracy: 0.7732 - val_loss: 0.7030 - val_accuracy: 0.6357\n",
      "Epoch 28/100\n",
      "280/280 [==============================] - 0s 802us/step - loss: 0.4601 - accuracy: 0.7771 - val_loss: 0.7206 - val_accuracy: 0.6353\n",
      "Epoch 29/100\n",
      "280/280 [==============================] - 0s 804us/step - loss: 0.4565 - accuracy: 0.7798 - val_loss: 0.7165 - val_accuracy: 0.6299\n",
      "Epoch 30/100\n",
      "280/280 [==============================] - 0s 775us/step - loss: 0.4519 - accuracy: 0.7816 - val_loss: 0.7445 - val_accuracy: 0.6330\n",
      "Epoch 31/100\n",
      "280/280 [==============================] - 0s 844us/step - loss: 0.4537 - accuracy: 0.7817 - val_loss: 0.7306 - val_accuracy: 0.6424\n",
      "Epoch 32/100\n",
      "280/280 [==============================] - 0s 788us/step - loss: 0.4379 - accuracy: 0.7915 - val_loss: 0.7424 - val_accuracy: 0.6371\n",
      "Epoch 33/100\n",
      "280/280 [==============================] - 0s 830us/step - loss: 0.4360 - accuracy: 0.7948 - val_loss: 0.7446 - val_accuracy: 0.6272\n",
      "Epoch 34/100\n",
      "280/280 [==============================] - 0s 715us/step - loss: 0.4345 - accuracy: 0.7929 - val_loss: 0.7510 - val_accuracy: 0.6295\n",
      "Epoch 35/100\n",
      "280/280 [==============================] - 0s 700us/step - loss: 0.4294 - accuracy: 0.7935 - val_loss: 0.7772 - val_accuracy: 0.6281\n",
      "Epoch 36/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.4310 - accuracy: 0.7960 - val_loss: 0.7563 - val_accuracy: 0.6299\n",
      "Epoch 37/100\n",
      "280/280 [==============================] - 0s 704us/step - loss: 0.4248 - accuracy: 0.7953 - val_loss: 0.7685 - val_accuracy: 0.6286\n",
      "Epoch 38/100\n",
      "280/280 [==============================] - 0s 690us/step - loss: 0.4201 - accuracy: 0.7983 - val_loss: 0.7688 - val_accuracy: 0.6254\n",
      "Epoch 39/100\n",
      "280/280 [==============================] - 0s 694us/step - loss: 0.4231 - accuracy: 0.7967 - val_loss: 0.7663 - val_accuracy: 0.6295\n",
      "Epoch 40/100\n",
      "280/280 [==============================] - 0s 701us/step - loss: 0.4110 - accuracy: 0.8048 - val_loss: 0.7939 - val_accuracy: 0.6165\n",
      "Epoch 41/100\n",
      "280/280 [==============================] - 0s 702us/step - loss: 0.4087 - accuracy: 0.8026 - val_loss: 0.7821 - val_accuracy: 0.6295\n",
      "Epoch 42/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.4116 - accuracy: 0.8060 - val_loss: 0.8012 - val_accuracy: 0.6286\n",
      "Epoch 43/100\n",
      "280/280 [==============================] - 0s 709us/step - loss: 0.4001 - accuracy: 0.8112 - val_loss: 0.7976 - val_accuracy: 0.6263\n",
      "Epoch 44/100\n",
      "280/280 [==============================] - 0s 826us/step - loss: 0.4044 - accuracy: 0.8093 - val_loss: 0.7921 - val_accuracy: 0.6210\n",
      "Epoch 45/100\n",
      "280/280 [==============================] - 0s 755us/step - loss: 0.3966 - accuracy: 0.8114 - val_loss: 0.7934 - val_accuracy: 0.6259\n",
      "Epoch 46/100\n",
      "280/280 [==============================] - 0s 783us/step - loss: 0.3954 - accuracy: 0.8162 - val_loss: 0.8283 - val_accuracy: 0.6348\n",
      "Epoch 47/100\n",
      "280/280 [==============================] - 0s 867us/step - loss: 0.3888 - accuracy: 0.8173 - val_loss: 0.8172 - val_accuracy: 0.6237\n",
      "Epoch 48/100\n",
      "280/280 [==============================] - 0s 839us/step - loss: 0.3881 - accuracy: 0.8199 - val_loss: 0.8099 - val_accuracy: 0.6290\n",
      "Epoch 49/100\n",
      "280/280 [==============================] - 0s 739us/step - loss: 0.3890 - accuracy: 0.8194 - val_loss: 0.8187 - val_accuracy: 0.6156\n",
      "Epoch 50/100\n",
      "280/280 [==============================] - 0s 717us/step - loss: 0.3906 - accuracy: 0.8164 - val_loss: 0.8101 - val_accuracy: 0.6237\n",
      "Epoch 51/100\n",
      "280/280 [==============================] - 0s 707us/step - loss: 0.3785 - accuracy: 0.8230 - val_loss: 0.8293 - val_accuracy: 0.6277\n",
      "Epoch 52/100\n",
      "280/280 [==============================] - 0s 814us/step - loss: 0.3872 - accuracy: 0.8191 - val_loss: 0.8295 - val_accuracy: 0.6254\n",
      "Epoch 53/100\n",
      "280/280 [==============================] - 0s 800us/step - loss: 0.3751 - accuracy: 0.8224 - val_loss: 0.8515 - val_accuracy: 0.6165\n",
      "Epoch 54/100\n",
      "280/280 [==============================] - 0s 853us/step - loss: 0.3769 - accuracy: 0.8275 - val_loss: 0.8451 - val_accuracy: 0.6205\n",
      "Epoch 55/100\n",
      "280/280 [==============================] - 0s 851us/step - loss: 0.3734 - accuracy: 0.8313 - val_loss: 0.8522 - val_accuracy: 0.6246\n",
      "Epoch 56/100\n",
      "280/280 [==============================] - 0s 779us/step - loss: 0.3676 - accuracy: 0.8319 - val_loss: 0.8433 - val_accuracy: 0.6067\n",
      "Epoch 57/100\n",
      "280/280 [==============================] - 0s 721us/step - loss: 0.3616 - accuracy: 0.8360 - val_loss: 0.8554 - val_accuracy: 0.6161\n",
      "Epoch 58/100\n",
      "280/280 [==============================] - 0s 699us/step - loss: 0.3583 - accuracy: 0.8359 - val_loss: 0.8736 - val_accuracy: 0.6094\n",
      "Epoch 59/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.3578 - accuracy: 0.8324 - val_loss: 0.8880 - val_accuracy: 0.6116\n",
      "Epoch 60/100\n",
      "280/280 [==============================] - 0s 721us/step - loss: 0.3611 - accuracy: 0.8346 - val_loss: 0.8759 - val_accuracy: 0.6241\n",
      "Epoch 61/100\n",
      "280/280 [==============================] - 0s 756us/step - loss: 0.3650 - accuracy: 0.8376 - val_loss: 0.8583 - val_accuracy: 0.6121\n",
      "Epoch 62/100\n",
      "280/280 [==============================] - 0s 703us/step - loss: 0.3632 - accuracy: 0.8315 - val_loss: 0.8811 - val_accuracy: 0.6152\n",
      "Epoch 63/100\n",
      "280/280 [==============================] - 0s 702us/step - loss: 0.3634 - accuracy: 0.8300 - val_loss: 0.8682 - val_accuracy: 0.5960\n",
      "Epoch 64/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.3593 - accuracy: 0.8360 - val_loss: 0.8523 - val_accuracy: 0.6143\n",
      "Epoch 65/100\n",
      "280/280 [==============================] - 0s 691us/step - loss: 0.3528 - accuracy: 0.8357 - val_loss: 0.8867 - val_accuracy: 0.6134\n",
      "Epoch 66/100\n",
      "280/280 [==============================] - 0s 727us/step - loss: 0.3449 - accuracy: 0.8484 - val_loss: 0.8664 - val_accuracy: 0.6187\n",
      "Epoch 67/100\n",
      "280/280 [==============================] - 0s 807us/step - loss: 0.3542 - accuracy: 0.8330 - val_loss: 0.8716 - val_accuracy: 0.6121\n",
      "Epoch 68/100\n",
      "280/280 [==============================] - 0s 775us/step - loss: 0.3468 - accuracy: 0.8394 - val_loss: 0.8781 - val_accuracy: 0.6116\n",
      "Epoch 69/100\n",
      "280/280 [==============================] - 0s 741us/step - loss: 0.3410 - accuracy: 0.8433 - val_loss: 0.9019 - val_accuracy: 0.6187\n",
      "Epoch 70/100\n",
      "280/280 [==============================] - 0s 705us/step - loss: 0.3453 - accuracy: 0.8429 - val_loss: 0.9001 - val_accuracy: 0.6147\n",
      "Epoch 71/100\n",
      "280/280 [==============================] - 0s 722us/step - loss: 0.3491 - accuracy: 0.8422 - val_loss: 0.8851 - val_accuracy: 0.6107\n",
      "Epoch 72/100\n",
      "280/280 [==============================] - 0s 718us/step - loss: 0.3369 - accuracy: 0.8469 - val_loss: 0.9034 - val_accuracy: 0.6045\n",
      "Epoch 73/100\n",
      "280/280 [==============================] - 0s 719us/step - loss: 0.3332 - accuracy: 0.8508 - val_loss: 0.9185 - val_accuracy: 0.6187\n",
      "Epoch 74/100\n",
      "280/280 [==============================] - 0s 722us/step - loss: 0.3419 - accuracy: 0.8439 - val_loss: 0.9104 - val_accuracy: 0.6165\n",
      "Epoch 75/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.3457 - accuracy: 0.8483 - val_loss: 0.9033 - val_accuracy: 0.6192\n",
      "Epoch 76/100\n",
      "280/280 [==============================] - 0s 701us/step - loss: 0.3339 - accuracy: 0.8433 - val_loss: 0.9112 - val_accuracy: 0.6138\n",
      "Epoch 77/100\n",
      "280/280 [==============================] - 0s 723us/step - loss: 0.3331 - accuracy: 0.8473 - val_loss: 0.9086 - val_accuracy: 0.6049\n",
      "Epoch 78/100\n",
      "280/280 [==============================] - 0s 692us/step - loss: 0.3338 - accuracy: 0.8479 - val_loss: 0.9414 - val_accuracy: 0.5991\n",
      "Epoch 79/100\n",
      "280/280 [==============================] - 0s 925us/step - loss: 0.3332 - accuracy: 0.8484 - val_loss: 0.9412 - val_accuracy: 0.6080\n",
      "Epoch 80/100\n",
      "280/280 [==============================] - 0s 831us/step - loss: 0.3373 - accuracy: 0.8481 - val_loss: 0.9237 - val_accuracy: 0.6085\n",
      "Epoch 81/100\n",
      "280/280 [==============================] - 0s 788us/step - loss: 0.3329 - accuracy: 0.8491 - val_loss: 0.9256 - val_accuracy: 0.6107\n",
      "Epoch 82/100\n",
      "280/280 [==============================] - 0s 720us/step - loss: 0.3385 - accuracy: 0.8436 - val_loss: 0.9150 - val_accuracy: 0.6045\n",
      "Epoch 83/100\n",
      "280/280 [==============================] - 0s 702us/step - loss: 0.3253 - accuracy: 0.8547 - val_loss: 0.9267 - val_accuracy: 0.6054\n",
      "Epoch 84/100\n",
      "280/280 [==============================] - 0s 690us/step - loss: 0.3129 - accuracy: 0.8599 - val_loss: 0.9435 - val_accuracy: 0.6049\n",
      "Epoch 85/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.3226 - accuracy: 0.8539 - val_loss: 0.9432 - val_accuracy: 0.6076\n",
      "Epoch 86/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.3227 - accuracy: 0.8569 - val_loss: 0.9428 - val_accuracy: 0.6129\n",
      "Epoch 87/100\n",
      "280/280 [==============================] - 0s 697us/step - loss: 0.3188 - accuracy: 0.8550 - val_loss: 0.9439 - val_accuracy: 0.6143\n",
      "Epoch 88/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.3164 - accuracy: 0.8576 - val_loss: 0.9405 - val_accuracy: 0.6040\n",
      "Epoch 89/100\n",
      "280/280 [==============================] - 0s 706us/step - loss: 0.3157 - accuracy: 0.8566 - val_loss: 0.9387 - val_accuracy: 0.6134\n",
      "Epoch 90/100\n",
      "280/280 [==============================] - 0s 699us/step - loss: 0.3069 - accuracy: 0.8594 - val_loss: 0.9681 - val_accuracy: 0.6098\n",
      "Epoch 91/100\n",
      "280/280 [==============================] - 0s 698us/step - loss: 0.3148 - accuracy: 0.8589 - val_loss: 0.9622 - val_accuracy: 0.6103\n",
      "Epoch 92/100\n",
      "280/280 [==============================] - 0s 696us/step - loss: 0.3136 - accuracy: 0.8592 - val_loss: 0.9323 - val_accuracy: 0.6076\n",
      "Epoch 93/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.3213 - accuracy: 0.8580 - val_loss: 0.9522 - val_accuracy: 0.6107\n",
      "Epoch 94/100\n",
      "280/280 [==============================] - 0s 697us/step - loss: 0.3089 - accuracy: 0.8632 - val_loss: 0.9784 - val_accuracy: 0.6112\n",
      "Epoch 95/100\n",
      "280/280 [==============================] - 0s 700us/step - loss: 0.3191 - accuracy: 0.8576 - val_loss: 0.9574 - val_accuracy: 0.5996\n",
      "Epoch 96/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.3042 - accuracy: 0.8652 - val_loss: 0.9684 - val_accuracy: 0.6107\n",
      "Epoch 97/100\n",
      "280/280 [==============================] - 0s 695us/step - loss: 0.3068 - accuracy: 0.8646 - val_loss: 0.9698 - val_accuracy: 0.6085\n",
      "Epoch 98/100\n",
      "280/280 [==============================] - 0s 699us/step - loss: 0.2974 - accuracy: 0.8673 - val_loss: 0.9990 - val_accuracy: 0.6089\n",
      "Epoch 99/100\n",
      "280/280 [==============================] - 0s 699us/step - loss: 0.3027 - accuracy: 0.8655 - val_loss: 1.0092 - val_accuracy: 0.6161\n",
      "Epoch 100/100\n",
      "280/280 [==============================] - 0s 697us/step - loss: 0.3000 - accuracy: 0.8664 - val_loss: 0.9778 - val_accuracy: 0.6112\n",
      "88/88 [==============================] - 0s 357us/step\n",
      "Accuracy: 0.6107\n",
      "88/88 [==============================] - 0s 322us/step\n",
      "ROC AUC Score: 0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ... (Kode sebelumnya untuk pra-pemrosesan data Anda)\n",
    "\n",
    "# # Split Train vs Test Data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Penskalaan fitur\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Membangun model Deep Learning dengan Keras\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Mengevaluasi model\n",
    "y_pred_raw = model.predict(X_test_scaled)\n",
    "y_pred_class = (y_pred_raw > 0.5).astype(int).flatten()\n",
    "accuracy = np.mean(y_pred_class == y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "y_pred_prob = model.predict(X_test_scaled).flatten()\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Menyimpan model\n",
    "model.save(\"deep_learning_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ddea66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_dir/keras_tuner_demo/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 14\n",
      "units_input (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_input (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "n_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_1 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_3 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "dropout_4 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.05, 'sampling': 'linear'}\n",
      "Results summary\n",
      "Results in keras_tuner_dir/keras_tuner_demo\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units_input: 224\n",
      "dropout_input: 0.30000000000000004\n",
      "n_layers: 3\n",
      "units_0: 448\n",
      "dropout_0: 0.25\n",
      "learning_rate: 0.001\n",
      "units_1: 64\n",
      "dropout_1: 0.2\n",
      "units_2: 256\n",
      "dropout_2: 0.0\n",
      "units_3: 416\n",
      "dropout_3: 0.25\n",
      "units_4: 96\n",
      "dropout_4: 0.4\n",
      "Score: 0.6642857193946838\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units_input: 512\n",
      "dropout_input: 0.1\n",
      "n_layers: 3\n",
      "units_0: 512\n",
      "dropout_0: 0.35000000000000003\n",
      "learning_rate: 0.001\n",
      "units_1: 32\n",
      "dropout_1: 0.0\n",
      "units_2: 32\n",
      "dropout_2: 0.0\n",
      "Score: 0.6611607074737549\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units_input: 32\n",
      "dropout_input: 0.1\n",
      "n_layers: 5\n",
      "units_0: 128\n",
      "dropout_0: 0.35000000000000003\n",
      "learning_rate: 0.0001\n",
      "units_1: 512\n",
      "dropout_1: 0.05\n",
      "units_2: 416\n",
      "dropout_2: 0.25\n",
      "units_3: 32\n",
      "dropout_3: 0.0\n",
      "units_4: 32\n",
      "dropout_4: 0.0\n",
      "Score: 0.648809532324473\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units_input: 64\n",
      "dropout_input: 0.1\n",
      "n_layers: 4\n",
      "units_0: 480\n",
      "dropout_0: 0.1\n",
      "learning_rate: 0.01\n",
      "units_1: 384\n",
      "dropout_1: 0.4\n",
      "units_2: 32\n",
      "dropout_2: 0.15000000000000002\n",
      "units_3: 96\n",
      "dropout_3: 0.1\n",
      "units_4: 224\n",
      "dropout_4: 0.15000000000000002\n",
      "Score: 0.568154772122701\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units_input: 384\n",
      "dropout_input: 0.05\n",
      "n_layers: 5\n",
      "units_0: 384\n",
      "dropout_0: 0.0\n",
      "learning_rate: 0.01\n",
      "units_1: 480\n",
      "dropout_1: 0.45\n",
      "units_2: 160\n",
      "dropout_2: 0.2\n",
      "units_3: 128\n",
      "dropout_3: 0.15000000000000002\n",
      "units_4: 64\n",
      "dropout_4: 0.30000000000000004\n",
      "Score: 0.5104166666666666\n",
      "88/88 [==============================] - 0s 534us/step\n",
      "Accuracy: 0.6414\n",
      "ROC AUC Score: 0.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baskoronugroho/python-projects/telkom-athon-ds/venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# ... (Kode pra-pemrosesan Anda)\n",
    "\n",
    "# Split Train vs Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Penskalaan fitur\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units_input',    \n",
    "                                        min_value=32,    \n",
    "                                        max_value=512,   \n",
    "                                        step=32),\n",
    "                           activation='relu',\n",
    "                           input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout_input',\n",
    "                                           min_value=0.0,\n",
    "                                           max_value=0.5,\n",
    "                                           step=0.05)))\n",
    "    for i in range(hp.Int('n_layers', 1, 5)):  \n",
    "        model.add(layers.Dense(units=hp.Int(f'units_{i}', 32, 512, 32),\n",
    "                               activation='relu'))\n",
    "        model.add(layers.Dropout(rate=hp.Float(f'dropout_{i}', 0.0, 0.5, step=0.05)))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "                    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,                 \n",
    "    objective='val_accuracy',    \n",
    "    max_trials=5,                \n",
    "    executions_per_trial=3,     \n",
    "    directory='keras_tuner_dir', \n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Mengevaluasi model terbaik\n",
    "y_pred_prob = best_model.predict(X_test_scaled).flatten()\n",
    "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "accuracy = np.mean(y_pred_class == y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Menyimpan model terbaik\n",
    "best_model.save(\"deep_learning_best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67220d3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb2aa31",
   "metadata": {},
   "source": [
    "### Coba Data Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e3511a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil data baru\n",
    "df_predict = run_query(\"coba4.sql\")\n",
    "\n",
    "# Menghapus kolom ID\n",
    "#new_data.drop(columns=['reco_id_curr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfa4af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         reco_id_curr  predicted_proba\n",
      "0    38027ebd59e7c2614201a9ad29d91f33         0.098205\n",
      "1    f7825cc89df0a3665baddede33a196f0         0.125623\n",
      "2    73ed7df79781a75b16431fc4c9dd50e9         0.240492\n",
      "3    bec10049923a0bb209a2044d06a96e86         0.332084\n",
      "4    8095e640b1088676e43264eb470b4806         0.401018\n",
      "..                                ...              ...\n",
      "995  a613d20807ab1699d07446e7925e1d1e         0.608887\n",
      "996  4d10b7b0ff7f5d4654c0a6d25661a19f         0.191180\n",
      "997  b2c36586339db9b42f1f140ee10c1dee         0.534942\n",
      "998  0de9581c9037f50a115908a386d859fd         0.447751\n",
      "999  7a80d7cd89b7e5378e29ea8d624c392f         0.211924\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 2. Pra-pemrosesan data\n",
    "# Simpan kolom 'reco_id_curr' untuk digabungkan lagi nanti\n",
    "reco_id_curr = df_predict['reco_id_curr'].copy()\n",
    "df_predict.drop(columns=['reco_id_curr'], inplace=True)\n",
    "\n",
    "# Mengisi missing values\n",
    "for col in df_predict.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df_predict[col].fillna(df_predict[col].median(), inplace=True)\n",
    "for col in df_predict.select_dtypes(include=['object']).columns:\n",
    "    df_predict[col].fillna(df_predict[col].mode()[0], inplace=True)\n",
    "\n",
    "# Label Encoding kolom kategorikal\n",
    "label_encoders = joblib.load('label_encoders.pkl')\n",
    "for col in df_predict.select_dtypes(include=['object']).columns:\n",
    "    if col in label_encoders:\n",
    "        df_predict[col] = label_encoders[col].transform(df_predict[col])\n",
    "\n",
    "# Penskalaan fitur\n",
    "scaler = joblib.load('data_scaler.pkl')\n",
    "df_predict_scaled = scaler.transform(df_predict)\n",
    "\n",
    "# 3. Prediksi menggunakan probabilitas\n",
    "model_name = 'xgboost_model'\n",
    "model = joblib.load(f'{model_name}.pkl')\n",
    "predicted_proba = model.predict_proba(df_predict_scaled)[:, 1]\n",
    "\n",
    "# 4. Gabungkan probabilitas prediksi dengan reco_id_curr dalam DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'reco_id_curr': reco_id_curr,\n",
    "    'predicted_proba': predicted_proba\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8051259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 618us/step\n",
      "                         reco_id_curr  predicted_proba\n",
      "0    38027ebd59e7c2614201a9ad29d91f33         0.280072\n",
      "1    f7825cc89df0a3665baddede33a196f0         0.110867\n",
      "2    73ed7df79781a75b16431fc4c9dd50e9         0.202840\n",
      "3    bec10049923a0bb209a2044d06a96e86         0.163998\n",
      "4    8095e640b1088676e43264eb470b4806         0.322483\n",
      "..                                ...              ...\n",
      "995  a613d20807ab1699d07446e7925e1d1e         0.501365\n",
      "996  4d10b7b0ff7f5d4654c0a6d25661a19f         0.394263\n",
      "997  b2c36586339db9b42f1f140ee10c1dee         0.439965\n",
      "998  0de9581c9037f50a115908a386d859fd         0.291561\n",
      "999  7a80d7cd89b7e5378e29ea8d624c392f         0.127701\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# 2. Pra-pemrosesan data\n",
    "# Simpan kolom 'reco_id_curr' untuk digabungkan lagi nanti\n",
    "reco_id_curr = df_predict['reco_id_curr'].copy()\n",
    "df_predict.drop(columns=['reco_id_curr'], inplace=True)\n",
    "\n",
    "# Mengisi missing values\n",
    "for col in df_predict.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df_predict[col].fillna(df_predict[col].median(), inplace=True)\n",
    "for col in df_predict.select_dtypes(include=['object']).columns:\n",
    "    df_predict[col].fillna(df_predict[col].mode()[0], inplace=True)\n",
    "\n",
    "# Label Encoding kolom kategorikal\n",
    "label_encoders = joblib.load('label_encoders.pkl')\n",
    "for col in df_predict.select_dtypes(include=['object']).columns:\n",
    "    if col in label_encoders:\n",
    "        df_predict[col] = label_encoders[col].transform(df_predict[col])\n",
    "\n",
    "# Penskalaan fitur\n",
    "scaler = joblib.load('data_scaler.pkl')\n",
    "df_predict_scaled = scaler.transform(df_predict)\n",
    "\n",
    "# 3. Muat dan prediksi menggunakan model deep learning\n",
    "model = tf.keras.models.load_model('deep_learning_best_model.h5')\n",
    "predicted_proba = model.predict(df_predict_scaled)[:, 0]  # Mengambil probabilitas dari kelas positif\n",
    "\n",
    "# 4. Gabungkan probabilitas prediksi dengan reco_id_curr dalam DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'reco_id_curr': reco_id_curr,\n",
    "    'predicted_proba': predicted_proba\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "141edd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92fa6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file telah dibuat! output_deep_learning_2023_09_25_17_23.csv\n"
     ]
    }
   ],
   "source": [
    "# Baca example_df dari file CSV dan hanya ambil kolom reco_id_curr dan urut\n",
    "example_df = pd.read_csv('./example_submission.csv', usecols=['reco_id_curr', 'urut'], sep=';')\n",
    "\n",
    "# Rename kolom predicted_proba menjadi target pada df\n",
    "result_df.rename(columns={'predicted_proba': 'target'}, inplace=True)\n",
    "\n",
    "# Lakukan inner join antara df dan example_df berdasarkan kolom reco_id_curr\n",
    "merged_df = pd.merge(result_df, example_df, on='reco_id_curr', how='inner')\n",
    "\n",
    "# Urutkan merged_df berdasarkan kolom urut\n",
    "merged_df.sort_values(by='urut', inplace=True)\n",
    "\n",
    "current_time = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "model_name = 'deep_learning'\n",
    "filename = f\"output_{model_name}_{current_time}.csv\"\n",
    "# Simpan DataFrame ke file CSV dengan hanya mengambil kolom reco_id_curr dan target\n",
    "merged_df[['reco_id_curr', 'target']].to_csv(filename, index=False, sep=',')\n",
    "\n",
    "print(f\"CSV file telah dibuat! {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1959ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.0.0\n",
      "appnope==0.1.3\n",
      "asttokens==2.4.0\n",
      "astunparse==1.6.3\n",
      "backcall==0.2.0\n",
      "cachetools==5.3.1\n",
      "certifi==2023.7.22\n",
      "charset-normalizer==3.2.0\n",
      "comm==0.1.4\n",
      "contourpy==1.1.1\n",
      "cycler==0.11.0\n",
      "debugpy==1.8.0\n",
      "decorator==5.1.1\n",
      "dm-tree==0.1.8\n",
      "exceptiongroup==1.1.3\n",
      "executing==1.2.0\n",
      "flatbuffers==23.5.26\n",
      "fonttools==4.42.1\n",
      "gast==0.4.0\n",
      "google-auth-oauthlib==1.0.0\n",
      "google-auth==2.23.0\n",
      "google-pasta==0.2.0\n",
      "grpcio==1.58.0\n",
      "h5py==3.9.0\n",
      "idna==3.4\n",
      "ipykernel==6.25.2\n",
      "ipython==8.15.0\n",
      "jedi==0.19.0\n",
      "joblib==1.3.2\n",
      "jupyter-client==8.3.1\n",
      "jupyter-core==5.3.1\n",
      "keras-core==0.1.7\n",
      "keras-tuner==1.4.0\n",
      "keras==2.13.1\n",
      "kiwisolver==1.4.5\n",
      "kt-legacy==1.0.5\n",
      "libclang==16.0.6\n",
      "lightgbm==4.0.0\n",
      "markdown-it-py==3.0.0\n",
      "markdown==3.4.4\n",
      "markupsafe==2.1.3\n",
      "matplotlib-inline==0.1.6\n",
      "matplotlib==3.7.1\n",
      "mdurl==0.1.2\n",
      "mysql-connector-python==8.1.0\n",
      "namex==0.0.7\n",
      "nest-asyncio==1.5.8\n",
      "numpy==1.24.3\n",
      "oauthlib==3.2.2\n",
      "opt-einsum==3.3.0\n",
      "packaging==23.1\n",
      "pandas==1.5.3\n",
      "parso==0.8.3\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "pillow==10.0.1\n",
      "pip==23.2.1\n",
      "platformdirs==3.10.0\n",
      "prompt-toolkit==3.0.39\n",
      "protobuf==4.21.12\n",
      "psutil==5.9.5\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pyasn1-modules==0.3.0\n",
      "pyasn1==0.5.0\n",
      "pygments==2.16.1\n",
      "pyparsing==3.1.1\n",
      "python-dateutil==2.8.2\n",
      "pytz==2023.3.post1\n",
      "pyzmq==25.1.1\n",
      "requests-oauthlib==1.3.1\n",
      "requests==2.31.0\n",
      "rich==13.5.3\n",
      "rsa==4.9\n",
      "scikit-learn==1.3.0\n",
      "scipy==1.11.2\n",
      "seaborn==0.12.2\n",
      "setuptools==65.5.0\n",
      "six==1.16.0\n",
      "sqlalchemy==1.4.39\n",
      "stack-data==0.6.2\n",
      "tensorboard-data-server==0.7.1\n",
      "tensorboard==2.13.0\n",
      "tensorflow-estimator==2.13.0\n",
      "tensorflow-macos==2.13.0\n",
      "tensorflow==2.13.0\n",
      "termcolor==2.3.0\n",
      "threadpoolctl==3.2.0\n",
      "tornado==6.3.3\n",
      "traitlets==5.10.0\n",
      "typing-extensions==4.5.0\n",
      "urllib3==1.26.16\n",
      "wcwidth==0.2.6\n",
      "werkzeug==2.3.7\n",
      "wheel==0.41.2\n",
      "wrapt==1.15.0\n",
      "xgboost==1.7.6\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "installed_packages = pkg_resources.working_set\n",
    "installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version) for i in installed_packages])\n",
    "for m in installed_packages_list:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a5e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
